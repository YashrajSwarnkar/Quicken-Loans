# -*- coding: utf-8 -*-
"""QuickenLoans_Bankmarketing_assessment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-CUl5iv77PiGTZLZLUDTjcQ3xka8zR0h

## **Bank Marketing Data set analytics**
"""

# Commented out IPython magic to ensure Python compatibility.
#importing requried Libraries
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('darkgrid')

#read csv file
banking_df = pd.read_csv('/content/DSA Data Set.csv')

#Printing first 5 rows of dataset
banking_df.head()

#Checking total number of columns and records in data and 
print('Shape of dataframe :',banking_df.shape)

#Checking dtype of all the columns
banking_df.dtypes

"""### **Exploratory Data Analytics**"""

#Statistical summary of data
banking_df.describe()

#Checking null values in dataset
banking_df.isnull().sum()

# Extracting categorical variables from dataset.
# Data majorly contains 2 types of variable numberic and categorical. Data having dtype "Object" is Categorical variable

cat_col = [n for n in banking_df.columns if banking_df[n].dtypes == 'object']
cat_col

#Obtaining the value count of each category column 
for col in cat_col:
    print(col, '\n')
    print(banking_df[col].value_counts())
    print("======================" * 2)

#Check the percentage of subscriber to non subscriber
No_sub = len(banking_df[banking_df['y'] == 'no'])
Sub = len(banking_df[banking_df['y'] == 'yes'])
percent_No_sub = (No_sub/len(banking_df['y'])) * 100
percent_sub = (Sub/len(banking_df['y'])) * 100

print('Percentage of subsription : ',percent_sub)
print('Percentage of no subscription : ', percent_No_sub)


df['y'].value_counts().plot.bar()

"""### **Data Visualization**"""

#Visualization from our categorical datas top see if we can get insigts from there
for col in cat_col:
    pd.crosstab(banking_df[col], banking_df.y).plot(kind = 'bar')
    plt.title(col)

#Distribution of age in dataset
plt.figure(figsize = (10,6))
sns.distplot(a = df['age'], kde = False)

#Deleting model prediction column from dataset
del banking_df['ModelPrediction']

y1 = df['y']

#Exploratory Data Analysis
#for numerical variable

num_var = ["age","duration","campaign", "pdays", "previous","emp.var.rate", "cons.price.idx", "cons.conf.idx", "euribor3m", "nr.employed"]

for i in num_var:
  sns.boxplot(x = y1,y = i,data = banking_df)
  plt.show();

#correlation matrix to check correlation between variables
plt.figure(figsize=(14,7))
corr = banking_df.corr()
sns.heatmap(corr, annot=True)
plt.show()

#Scatter plot to check dependency of dependent variable on Number of calls and Duration of calls
banking_df['duration'] = banking_df['duration'].apply(lambda n:n/60).round(2)
duration_campaign = sns.scatterplot(x='duration', y='campaign',data = banking_df,
                     hue = 'y')

plt.axis([0,65,0,65])
plt.ylabel('Number of Calls')
plt.xlabel('Duration of Calls (Minutes)')
plt.title('The Relationship between the Number and Duration of Calls')
# Annotation
plt.show()

"""### **Feature Selection**"""

#Create dummy variable for the categorical data and drop first column to avoid dummy varibale trap
bank_df = pd.get_dummies(banking_df,columns = ['job','marital','education','default',
                                   'housing','loan','month',
                                   'day_of_week','poutcome'], drop_first = True)

bank_df.shape

#Advisable to always split your data before using oversampling techniques
contact = ({'cellular':0, 'telephone':1})
bank_df['contact'] = df['contact'].map(contact)
X = bank_df.loc[:,bank_df.columns != 'y']
y = bank_df.loc[:,bank_df.columns == 'y']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2 , random_state = 0)

print('shape of X_train : ',len(X_train), '\nshape of y_train : ',len(y_train))
print('\nshape of X_test  : ',len(X_test), '\nshape of y_test  : ',len(y_test))

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""### **Modeling**"""

#train model using logistic regression
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression()
clf.fit(X_train,y_train)
clf.score(X_train,y_train)

clf.score(X_test,y_test)

y_pred = clf.predict(X_test)
y_pred

"""### **Metrices Used for evaluation**"""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
cm

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))